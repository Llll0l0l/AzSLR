{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bc9ff0-6237-414d-be77-d0ac61110887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import InternVideo\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Set the multiprocessing start method to 'spawn'\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "# Load the pretrained model\n",
    "model = InternVideo.load_model(\"../../../InternVideo2/multi_modality/ckpt_new/InternVideo-MM-L-14 (1).ckpt\").cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4802cd71-fe65-4e98-aac8-28ab862f901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "class SignLanguageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file, header=None, delimiter=' ')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Define the columns since there is no header in the CSV\n",
    "        self.data.columns = ['video_path', 'label']\n",
    "\n",
    "        # Create a mapping from string labels to integer indices\n",
    "        self.label_to_index = {label: idx for idx, label in enumerate(self.data['label'].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        label_str = self.data.iloc[idx, 1]\n",
    "\n",
    "        # Load the video using InternVideo's function or another method, move to GPU\n",
    "        video = InternVideo.load_video(video_path).cuda()  # Ensure video tensor is on GPU\n",
    "\n",
    "        # Apply any transformations to the video\n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "\n",
    "        # Convert the string label to an integer using the mapping\n",
    "        label = self.label_to_index[label_str]\n",
    "        label = torch.tensor(label).long().cuda()  # Ensure the label is also on the GPU\n",
    "\n",
    "        return video, label\n",
    "\n",
    "# Define transformations without ToTensor\n",
    "transform = transforms.Compose([\n",
    "    # Assuming the video is already a tensor, add any tensor-based transforms here\n",
    "    # For example, normalization (if needed):\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = SignLanguageDataset('annotations/train.csv', 'annotations', transform=transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b721f7d-d1c5-4bce-af00-bb8fe64d6720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/l/miniconda3/envs/checkpoint/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/l/miniconda3/envs/checkpoint/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'SignLanguageDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# train_dataset = SignLanguageDataset(csv_file='path/to/your/csv_file.csv', root_dir='path/to/your/video/files')\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()  # Ensure loss is on GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for videos, labels in train_loader:\n",
    "        # Move inputs and labels to GPU\n",
    "        videos = videos.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(videos)  # Forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Optional: Save the trained model's state dict\n",
    "torch.save(model.state_dict(), 'intern_video_finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba94bc0-2e3e-4784-add8-9717fd394fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d2084-6ae5-4e63-af1d-fa576272aa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
